{
  "openapi": "3.0.0",
  "info": {
    "description": "DeepVISS (Deep Vision Interoperability Specification Standard) allows several computer vision solutions to produce, consume and exchange events in the same format.",
    "version": "1.3.0",
    "title": "DeepVISS OPS",
    "termsOfService": "https://deepviss.org",
    "contact": {
      "email": "office@deepviss.org"
    },
    "license": {
      "name": "Apache 2.0",
      "url": "https://www.apache.org/licenses/LICENSE-2.0.html"
    }
  },
  "tags": [
    {
      "name": "frame",
      "description": "Information about post-processed frames",
      "externalDocs": {
        "description": "Streaming API",
        "url": "https://deepviss.org"
      }
    },
    {
      "name": "analysis",
      "description": "End-points for image or image array analysis",
      "externalDocs": {
        "description": "Find out more",
        "url": "https://deepviss.org"
      }
    }
  ],
  "paths": {
    "/stream/Frames": {
      "get": {
        "tags": [
          "frame"
        ],
        "summary": "Retrieve last frames",
        "description": "Multiple status values can be provided with comma separated strings",
        "operationId": "GetLastFrames",
        "parameters": [
          {
            "in": "query",
            "name": "streamId",
            "schema": {
              "type": "string"
            },
            "description": "The identifier of the stream"
          }
        ],
        "responses": {
          "200": {
            "description": "successful operation",
            "content": {
              "application/json": {
                "schema": {
                  "type": "array",
                  "items": {
                    "$ref": "#/definitions/Frame"
                  }
                }
              }
            }
          },
          "400": {
            "description": "Invalid status value"
          }
        }
      }
    },
    "/analysis/ProcessingRequest": {
      "post": {
        "tags": [
          "analysis"
        ],
        "summary": "Analyze a specific frame",
        "description": "",
        "operationId": "ProcessingRequest",
        "parameters": [
          {
            "in": "query",
            "name": "streamId",
            "schema": {
              "type": "string"
            },
            "description": "The identifier of the stream"
          }
        ],
        "requestBody": {
          "description": "Deliver the image to be analyzed *Markdown*",
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ProcessingRequest"
              }
            },
            "application/xml": {
              "schema": {
                "$ref": "#/components/schemas/ProcessingRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "successful operation",
            "content": {
              "application/json": {
                "schema": {
                  "type": "array",
                  "items": {
                    "$ref": "#/definitions/Frame"
                  }
                }
              }
            }
          },
          "400": {
            "description": "Invalid status value"
          }
        }
      }
    },
    "/analysis/ImagesArray": {
      "post": {
        "tags": [
          "analysis"
        ],
        "summary": "Analyze an array of images",
        "description": "",
        "operationId": "ImageArrayAnalysis",
        "parameters": [
          {
            "in": "query",
            "name": "streamId",
            "schema": {
              "type": "string"
            },
            "description": "The identifier of the stream"
          }
        ],
        "requestBody": {
          "description": "Deliver the image to be analyzed *Markdown*",
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "properties": {
                  "filename": {
                    "type": "array",
                    "items": {
                      "type": "string",
                      "format": "binary"
                    }
                  }
                }
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "successful operation",
            "content": {
              "application/json": {
                "schema": {
                  "type": "array",
                  "items": {
                    "$ref": "#/definitions/Frame"
                  }
                }
              }
            }
          },
          "400": {
            "description": "Invalid status value"
          }
        }
      }
    },
    "/analysis/Image": {
      "post": {
        "tags": [
          "analysis"
        ],
        "summary": "Analyze a single image",
        "description": "",
        "operationId": "ImageAnalysis",
        "parameters": [
          {
            "in": "query",
            "name": "streamId",
            "schema": {
              "type": "string"
            },
            "description": "The identifier of the stream"
          }
        ],
        "requestBody": {
          "description": "Deliver the image to be analyzed *Markdown*",
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "properties": {
                  "filename": {
                    "type": "array",
                    "items": {
                      "type": "string",
                      "format": "binary"
                    }
                  }
                }
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "successful operation",
            "content": {
              "application/json": {
                "schema": {
                  "type": "array",
                  "items": {
                    "$ref": "#/definitions/Frame"
                  }
                }
              }
            }
          },
          "400": {
            "description": "Invalid status value"
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "Frame": {
        "type": "object",
        "properties": {
          "timestamps": {
            "description": "Defines the several timestamps of acquisition, reception, pre-processing and post-processing respectively.",
            "type": "array",
            "items": {
              "type": "FrameTimestamp"
            }
          },
          "frameId": {
            "type": "string",
            "description": "Alpha-numeric, unique id of frame. You can use (timestamp+sourceId) or sha512(timestamp+sourceId)",
            "example": "7E43358680768EF053898993DD196397EDFDDFBC81751818B7FD1300124455B07E91CB289F87791D78064ECC93754F19B13D419489F162A150A22DD814CKAF0E"
          },
          "frameCounter": {
            "type": "integer",
            "format": "int32",
            "description": "Per-source incremental frame counter",
            "example": 86537
          },
          "sourceId": {
            "type": "string",
            "description": "Video source id."
          },
          "image": {
            "type": "Image",
            "description": "Image information"
          },
          "events": {
            "type": "array",
            "items": {
              "type": "Event"
            }
          },
          "timing": {
            "type": "object",
            "additionalProperties": {
              "type": "double"
            }
          },
          "debug": {
            "type": "object",
            "additionalProperties": {
              "type": "string"
            }
          }
        }
      },
      "Image": {
        "type": "object",
        "properties": {
          "imageURL": {
            "description": "The URL where the image is stored.",
            "type": "string"
          },
          "imageBase64": {
            "type": "string",
            "format": "byte",
            "description": "Base64 encoded string of the image."
          },
          "imageContentType": {
            "type": "string",
            "description": "Image MIME-type, such as image/png or image/jpeg"
          }
        }
      },
      "FrameTimestamp": {
        "type": "object",
        "properties": {
          "value": {
            "type": "string",
            "pattern": "/^(-?(?:[1-9][0-9]*)?[0-9]{4})-(1[0-2]|0[1-9])-(3[01]|0[1-9]|[12][0-9])T(2[0-3]|[01][0-9]):([0-5][0-9]):([0-5][0-9])(.[0-9]+)?(Z)?$/g",
            "description": "Date and time expressed according to ISO 8601 (e.g. 2018-06-24T23:10:28+03:00)"
          },
          "reference": {
            "type": "string",
            "enum": [
              "acquisition",
              "reception",
              "preprocessing",
              "postprocessing"
            ]
          }
        }
      },
      "Event": {
        "type": "object",
        "properties": {
          "objectType": {
            "type": "string",
            "description": "What type of event has been detected?",
            "example": "vehicle"
          },
          "id": {
            "type": "string",
            "description": "Unique or almost-unique hash or identifier of the detected event. Can be computed as dependant on frame timestamp, position of detection and event type.",
            "example": "T2NLg96Xosg7NLg96Xos"
          },
          "attributes": {
            "description": "What are the inferred attributes of the object?",
            "type": "array",
            "items": {
              "type": "Attribute"
            }
          },
          "tracking": {
            "type": "Tracking",
            "description": "Tracking id and tracking detection"
          },
          "detection": {
            "type": "Detection",
            "description": "Detection information"
          },
          "features": {
            "type": "Features",
            "description": "[DEPRECATED] The main features of detectected object."
          },
          "featuresMap": {
            "description": "What are the secondary features extracted from the detected object?",
            "type": "array",
            "items": {
              "type": "Features"
            }
          },
          "processedImage": {
            "type": "Image",
            "description": "Any post-processing image returned for this event."
          }
        }
      },
      "Detection": {
        "type": "object",
        "properties": {
          "boundingRectangle": {
            "type": "BoundingRectangle",
            "description": "Where in the frame has the object been detected?"
          },
          "orientation": {
            "type": "Orientation",
            "description": "What is the geometric orientation of the detected object or event?"
          },
          "algorithm": {
            "type": "string",
            "description": "What type of algorithm performed the detection",
            "example": "faster-rcnn"
          },
          "keypoints": {
            "description": "What are the keypoints of the object??",
            "type": "array",
            "items": {
              "type": "Point2D"
            }
          },
          "segmentedKeypoints": {
            "description": "What are the keypoints of the object??",
            "type": "array",
            "items": {
              "type": "KeypointsSegment"
            }
          },
          "confidence": {
            "type": "number",
            "format": "double",
            "description": "What is the confidence of the detection",
            "example": 0.9731
          }
        }
      },
      "BoundingRectangle": {
        "type": "object",
        "required": [
          "top",
          "left",
          "width",
          "height"
        ],
        "properties": {
          "top": {
            "description": "Top-most position, in pixels, of of the bounding rectangle",
            "type": "integer",
            "format": "int32",
            "example": 32
          },
          "left": {
            "description": "Left-most position, in pixels, of of the bounding rectangle",
            "type": "integer",
            "format": "int32",
            "example": 57
          },
          "width": {
            "description": "Width, in pixels, of the bounding rectangle",
            "type": "integer",
            "format": "int32",
            "example": 237
          },
          "height": {
            "description": "Height, in pixels, of the bounding rectangle",
            "type": "integer",
            "format": "int32",
            "example": 352
          }
        }
      },
      "Point2D": {
        "type": "object",
        "required": [
          "x",
          "y"
        ],
        "properties": {
          "x": {
            "description": "X-coordinate as integer number of pixels measured from the left to the right.",
            "type": "integer",
            "format": "int32"
          },
          "y": {
            "description": "Y-coordinate as integer number of pixels measured from the top to the bottom.",
            "type": "integer",
            "format": "int32"
          }
        }
      },
      "SourceStatus": {
        "type": "object",
        "required": [
          "id",
          "name"
        ],
        "properties": {
          "ingestedFrame": {
            "type": "integer",
            "format": "int32",
            "description": "Number of frame which have been successfully captured.",
            "example": 86537
          },
          "processedFrames": {
            "type": "integer",
            "format": "int32",
            "description": "Number of frame which have been successfully processed.",
            "example": 86537
          },
          "ingestedErrorCount": {
            "type": "integer",
            "format": "int32",
            "description": "Number of errors, dropped or missed frames from acquisition",
            "example": 86537
          },
          "processedErrorCount": {
            "type": "integer",
            "format": "int32",
            "description": "Number of errors, dropped or missed frames from processing",
            "example": 86537
          }
        }
      },
      "Source": {
        "type": "object",
        "required": [
          "id",
          "name"
        ],
        "properties": {
          "id": {
            "description": "Internal alphanumeric ID of video source",
            "type": "string"
          },
          "name": {
            "description": "Human-readable name of video source",
            "type": "string"
          },
          "vendor": {
            "description": "Vendor of the camera",
            "type": "string"
          },
          "model": {
            "description": "Model of the camera",
            "type": "string"
          },
          "stateless": {
            "description": "Set to true if stream is expected to have non-continous frames.",
            "type": "boolean"
          },
          "bounded": {
            "description": "Set to true if stream represents a finite-duration video (like a movie upload)",
            "type": "boolean"
          },
          "fixedPosition": {
            "description": "Set to true if camera is expected to move.",
            "type": "boolean"
          },
          "Position": {
            "description": "The geographic (physical) position of the camera",
            "type": "GeoPosition"
          },
          "connection": {
            "description": "Details on connection.",
            "type": "SourceConnection"
          }
        }
      },
      "Orientation": {
        "type": "object",
        "required": [
        ],
        "properties": {
          "yaw": {
            "description": "The yaw of the detected object or event.",
            "type": "number",
            "format": "double"
          },
          "pitch": {
            "description": "The pitch of the detected object or event.",
            "type": "number",
            "format": "double"
          },
          "roll": {
            "description": "The roll of the detected object or event.",
            "type": "number",
            "format": "double"
          }
        }
      },
      "Metric": {
        "description": "The recommended type of metric used ",
        "type": "string",
        "example": "Euclidean tripartite loss function",
        "enum": [
          "euclidean",
          "manhattan",
          "cosine"
        ]
      },
      "Features": {
        "type": "object",
        "required": [
          "features"
        ],
        "properties": {
          "algorithm": {
            "description": "The name and version of the algorithm used for feature extraction",
            "type": "string",
            "example": "Euclidean tripartite loss function"
          },
          "privacy": {
            "description": "The recommended type of metric used ",
            "type": "PrivacyIndication"
          },
          "metric": {
            "description": "The recommended type of metric used ",
            "type": "Metric"
          },
          "threshold": {
            "description": "The value of the metric threshold",
            "type": "number",
            "format": "double",
            "example": 0.8
          },
          "hash": {
            "description": "The hash of the features, for quick exact-match look-up",
            "type": "string",
            "example": "8e347f952424ec9dadb61ab399074362ade84f76f2e5e78de41978d1baa8aaadaace00ec5f93e57c8bfb92d07d5c248873f9ac7964027c80a4e4d0e88fa56459"
          },
          "vector": {
            "description": "N-dimensional feature vector of numerical features representing the unique signature of the object",
            "type": "array",
            "items": {
              "type": "number",
              "format": "double"
            }
          }
        }
      },
      "Attribute": {
        "type": "object",
        "required": [
          "name",
          "value"
        ],
        "properties": {
          "name": {
            "description": "The name of the attribute",
            "type": "string",
            "example": "age-group"
          },
          "value": {
            "description": "The value of the attribute",
            "type": "string",
            "example": "32-45"
          },
          "confidence": {
            "description": "The confidence of the classification",
            "type": "number",
            "format": "double",
            "example": 0.93
          },
          "type": {
            "description": "The type of the attribute, to be used in higher order processing and logic.",
            "type": "string",
            "enum": [
              "lexicographic",
              "hex-color",
              "integer",
              "double"
            ]
          }
        }
      },
      "ProcessingRequest": {
        "type": "object",
        "properties": {
          "image": {
            "type": "Image",
            "description": "Image information"
          },
          "regionsOfInterest": {
            "description": "Define any regions of interest, defined by bounding boxes, where the processing should focus.",
            "type": "array",
            "items": {
              "type": "BoundingRectangle"
            }
          },
          "parameters": {
            "type": "object",
            "additionalProperties": {
              "type": "string"
            }
          },
          "frameId": {
            "type": "string",
            "description": "Alpha-numeric, unique id of frame. You can use (timestamp+sourceId) or sha512(timestamp+sourceId)",
            "example": "7E43358680768EF053898993DD196397EDFDDFBC81751818B7FD1300124455B07E91CB289F87791D78064ECC93754F19B13D419489F162A150A22DD814CKAF0E"
          },
          "frameCounter": {
            "type": "integer",
            "format": "int32",
            "description": "Per-source incremental frame counter",
            "example": 86537
          },
          "sourceId": {
            "type": "string",
            "description": "Video source id."
          }
        }
      },
      "GeoPosition": {
        "type": "object",
        "required": [
          "latitude",
          "longitude"
        ],
        "properties": {
          "latitude": {
            "description": "The latitude at which the video source is installed.",
            "type": "number",
            "format": "double"
          },
          "longitude": {
            "description": "The longitude at which the video source is installed.",
            "type": "number",
            "format": "double"
          },
          "altitude": {
            "description": "The altitude at which the video source is installed.",
            "type": "number",
            "format": "double"
          },
          "elevation": {
            "description": "The elevation from the ground at which the video source is installed, measured in meters.",
            "type": "number",
            "format": "double"
          }
        }
      },
      "KeypointsSegment": {
        "type": "object",
        "properties": {
          "keypoints" : {
            "description" : "Collection of key-points, grouped in a map with keys representing names and values represented by a value of points.",
            "type": "array",
            "items": {
              "type": "Point2D"
            }
          }
        }
      },
      "SourceConnection": {
        "type": "object",
        "required": [
          "url",
          "protocol"
        ],
        "properties": {
          "url": {
            "description": "The hostname of the video source",
            "type": "string"
          },
          "username": {
            "description": "The username used for authentication to the video source",
            "type": "string"
          },
          "password": {
            "description": "The password used for authentication to the video source",
            "type": "string"
          },
          "protocol": {
            "type": "string",
            "description": "The protocol used to connect to the video source",
            "enum": [
              "jpeg_snapshot",
              "mjpeg",
              "h264_http",
              "hls",
              "webrtc",
              "image_push",
              "video_push"
            ]
          }
        }
      },
      "ObjectCollection": {
        "type": "object",
        "properties": {
          "id": {
            "description": "The ID of the collection",
            "type": "string"
          },
          "name": {
            "description": "The human-readable name of the collection",
            "type": "string"
          },
          "objectType": {
            "description": "The type of objects in the collection. A collection can only hold objects of the same type.",
            "type": "string"
          },
          "algorithm": {
            "description": "The name and version of the algorithm used for feature extraction. A collection can only hold objects with the same feature space (latent space).",
            "type": "string",
            "example": "Euclidean tripartite loss function"
          },
          "metric": {
            "description": "The metric used for comparing collection objects ",
            "type": "Metric"
          },
          "threshold": {
            "description": "The recommended metric value recommended to be used as threshold",
            "type": "number",
            "format": "double",
            "example": 0.8
          },
          "profiles": {
            "type": "ObjectProfile",
            "description": "List of ObjectProfiles. All profiles must be of the same type as the collection object type."
          }
        }
      },
      "ObjectProfile": {
        "type": "object",
        "properties": {
          "id": {
            "description": "The ID of the object profile, containing several ObjectInstance. ObjectProfiles belong to ObjectCollections.",
            "type": "string"
          },
          "externalId": {
            "description": "The ID of the object profile, containing several ObjectInstance. ObjectProfiles belong to ObjectCollections.",
            "type": "string"
          },
          "collectionId": {
            "description": "The ID of parent collection.",
            "type": "string"
          },
          "avatars": {
            "description": "The list of object instances statically assigned to the object profile.",
            "type": "array",
            "items": {
              "type": "string"
            }
          },
          "displayName": {
            "description": "The human-readable name of the profile",
            "type": "string"
          },
          "instances": {
            "description": "The list of object instances statically assigned to the object profile.",
            "type": "array",
            "items": {
              "type": "ObjectInstance"
            }
          },
          "attributes": {
            "type": "object",
            "additionalProperties": {
              "type": "string"
            }
          },
          "occurrences": {
            "description": "The list of object instances dynamically assigned to the object profile.",
            "type": "array",
            "items": {
              "type": "ObjectOccurrence"
            }
          }
        }
      },
      "ObjectInstance": {
        "type": "object",
        "properties": {
          "id": {
            "description": "The ID of the object instance, containing the feature vector. ObjectInstances belong to ObjectProfiles, which in turn belong to ObjectCollections.",
            "type": "string"
          },
          "profileId": {
            "description": "The ID of parent profile.",
            "type": "string"
          },
          "image": {
            "type": "Image",
            "description": "Original image information associated with the ObjectInstance"
          },
          "features": {
            "type": "Features",
            "description": "What are the features extracted from the detected object?"
          }
        }
      },
      "ObjectOccurrence": {
        "type": "object",
        "properties": {
          "sourceId": {
            "description": "The ID of the source from which the frame originated",
            "type": "string"
          },
          "timestamp": {
            "type": "FrameTimestamp",
            "description": "The timestamp of the frame from which match originated."
          },
          "eventId": {
            "description": "The ID of the object instance",
            "type": "string"
          },
          "objectInstanceId": {
            "type": "string",
            "description": "The id of the object instance."
          },
          "matches": {
            "description": "The list of profile that object matched as compared to a list of collections, at a specific time",
            "type": "array",
            "items": {
              "type": "ObjectMatch"
            }
          }
        }
      },
      "ObjectMatch": {
        "type": "object",
        "properties": {
          "matchType": {
            "description": "The match with an object",
            "type": "string"
          },
          "algorithm": {
            "description": "The name and version of the algorithm used for feature extraction",
            "type": "string",
            "example": "Euclidean tripartite loss function"
          },
          "metric": {
            "description": "The ID of the collection from which the match was made",
            "type": "string"
          },
          "collectionId": {
            "description": "The ID of the collection from which the match was made",
            "type": "string"
          },
          "profileId": {
            "description": "The ID of the profile that was matched.",
            "type": "string"
          },
          "matchRate": {
            "description": "The ID of the profile that was matched.",
            "type": "number",
            "format": "double",
            "example": 0.79
          }
        }
      },
      "ObjectBucket": {
        "description": "[TODO: Object definition] Unsorted and unassigned set of object occurences, which can server for clustering and later historical-matching.",
        "type": "object",
        "properties": {
          "id": {
            "description": "The ID of the bucket of object instances",
            "type": "string"
          }
        }
      },
      "Transcription": {
        "type": "object",
        "properties": {
          "text": {
            "description": "The ID of the collection from which the match was made",
            "type": "string"
          },
          "confidence": {
            "type": "number",
            "format": "double",
            "example": 0.83
          }
        }
      },
      "Tracking": {
        "type": "object",
        "properties": {
          "trackingId": {
            "description": "The tracking Id of the object",
            "type": "string"
          },
          "contextId": {
            "description": "The context from which the tracking originated",
            "type": "string"
          },
          "confidence": {
            "description": "The confidence that the object is tracked correctly and consistently.",
            "type": "number",
            "format": "double",
            "example": 0.83
          }
        }
      },
      "PrivacyIndication": {
        "type": "object",
        "properties": {
          "hasBiometricData": {
            "description": "Does object contain biometric data?",
            "type": "boolean"
          },
          "retentionAllowed": {
            "description": "Is retention of the object allowed?",
            "type": "boolean"
          },
          "scheduledEvictionTime": {
            "type": "string",
            "pattern": "/^(-?(?:[1-9][0-9]*)?[0-9]{4})-(1[0-2]|0[1-9])-(3[01]|0[1-9]|[12][0-9])T(2[0-3]|[01][0-9]):([0-5][0-9]):([0-5][0-9])(.[0-9]+)?(Z)?$/g",
            "description": "Date and time expressed according to ISO 8601 (e.g. 2018-06-24T23:10:28+03:00) of when this data is expected to be collected."
          }
        }
      },
      "PackedPrefetch": {
        "type": "object",
        "properties": {
          "profiles": {
            "type": "array",
            "items": {
              "type": "ObjectProfile"
            }
          }
        }
      },
      "PackedSight": {
        "type": "object",
        "properties": {
          "frames": {
            "type": "array",
            "items": {
              "type": "Frame"
            }
          },
          "occurrences": {
            "type": "array",
            "items": {
              "type": "ObjectOccurrence"
            }
          },
          "prefetch": {
            "type": "PackedPrefetch"
          }
        }
      }
    }
  },
  "externalDocs": {
    "description": "Deep vision interoperability specification standard (DeepVISS) reduces integration time, complexity and defects by using a standardized, language-agnostic, cross-platform schema",
    "url": "https://deepviss.org"
  }
}